{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "home_dir = \"../\"\n",
    "src_path = os.path.join(home_dir, \"src\")\n",
    "\n",
    "# Add the `src` folder to the Python path\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from functions import (compute_distance_correlation_matrix,\n",
    " compute_simplicial_complex_and_landscapes, compute_wto_matrix, compute_pearson_correlation_matrix,\n",
    "  patient_correlation_measure)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from cancer stages\n",
    "expression_matrix = pd.read_csv(\"../data/cancer_stage/fpkm_matrix.csv\", index_col=0)\n",
    "significant_genes = pd.read_csv(\"../data/cancer_stage/significant_genes.csv\", index_col=0)\n",
    "\n",
    "# Separate phenotype labels\n",
    "phenotype = expression_matrix[\"phenotype\"]\n",
    "expression_matrix = expression_matrix.drop(columns=[\"phenotype\"])\n",
    "\n",
    "# Select significant genes\n",
    "significant_gene_names = significant_genes.index\n",
    "sig_exp_matrix = expression_matrix[significant_gene_names.intersection(expression_matrix.columns)]\n",
    "\n",
    "top_var_genes_data = sig_exp_matrix\n",
    "gene_dict = {i: col_name for i, col_name in enumerate(top_var_genes_data.columns)}\n",
    "top_var_genes_data[\"phenotype\"] = phenotype.values\n",
    "\n",
    "stage1_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage1']\n",
    "stage2_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage2']\n",
    "stage3_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage3']\n",
    "stage4_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage4']\n",
    "\n",
    "stage1_top_var_genes_data = stage1_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "stage2_top_var_genes_data = stage2_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "stage3_top_var_genes_data = stage3_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "stage4_top_var_genes_data = stage4_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets for stage 1\n",
    "stage1_train, stage1_test = train_test_split(\n",
    "    stage1_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets for stage 2\n",
    "stage2_train, stage2_test = train_test_split(\n",
    "    stage2_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets for stage 3\n",
    "stage3_train, stage3_test = train_test_split(\n",
    "    stage3_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets for stage 4\n",
    "stage4_train, stage4_test = train_test_split(\n",
    "    stage4_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "stage1_distance_corr_matrix = compute_distance_correlation_matrix(stage1_train.values)\n",
    "stage2_distance_corr_matrix = compute_distance_correlation_matrix(stage2_train.values)\n",
    "stage3_distance_corr_matrix = compute_distance_correlation_matrix(stage3_train.values)\n",
    "stage4_distance_corr_matrix = compute_distance_correlation_matrix(stage4_train.values)\n",
    "\n",
    "# Define number of landscapes and resolution\n",
    "num_landscape = 2\n",
    "resolution = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 70.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 71.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:01<00:00, 70.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 69.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:01<00:00, 64.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 57.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:02<00:00, 58.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Computing the Simplicial Complex and persistence for patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 54.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list or empty diagrams: sample range is [-inf, -inf]\n",
      "First value and second value in range are the same: grid is made of resolution copies of this value\n",
      "Training Landscapes shape: (387, 600)\n",
      "Training Labels shape: (387,)\n",
      "Testing Landscapes shape: (99, 600)\n",
      "Testing Labels shape: (99,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Compute landscapes for training and testing sets for stage 1\n",
    "stage1_train_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage1_train.values, stage1_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "stage1_test_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage1_test.values, stage1_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "\n",
    "# Compute landscapes for training and testing sets for stage 2\n",
    "stage2_train_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage2_train.values, stage2_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "stage2_test_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage2_test.values, stage2_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "\n",
    "# Compute landscapes for training and testing sets for stage 3\n",
    "stage3_train_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage3_train.values, stage3_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "\n",
    "stage3_test_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage3_test.values, stage3_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "\n",
    "# Compute landscapes for training and testing sets for stage 4\n",
    "stage4_train_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage4_train.values, stage4_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "\n",
    "stage4_test_landscapes = compute_simplicial_complex_and_landscapes(\n",
    "    stage4_test.values, stage4_distance_corr_matrix, num_landscape, resolution\n",
    ")\n",
    "\n",
    "# Combine training landscapes\n",
    "train_landscapes = np.vstack([stage1_train_landscapes, stage2_train_landscapes, stage3_train_landscapes, stage4_train_landscapes])\n",
    "train_labels = np.concatenate([\n",
    "    np.full(stage1_train_landscapes.shape[0], 1),  # Label 1 for stage 1\n",
    "    np.full(stage2_train_landscapes.shape[0], 2),  # Label 2 for stage 2\n",
    "    np.full(stage3_train_landscapes.shape[0], 3),   # Label 3 for PCPG 3\n",
    "    np.full(stage4_train_landscapes.shape[0], 4)\n",
    "])\n",
    "\n",
    "# Combine testing landscapes\n",
    "test_landscapes = np.vstack([stage1_test_landscapes, stage2_test_landscapes, stage3_test_landscapes, stage4_test_landscapes])\n",
    "test_labels = np.concatenate([\n",
    "    np.full(stage1_test_landscapes.shape[0], 1),  # Label 1 for stage 1\n",
    "    np.full(stage2_test_landscapes.shape[0], 2),  # Label 2 for stage 2\n",
    "    np.full(stage3_test_landscapes.shape[0], 3),   # Label 3 for stage 3\n",
    "    np.full(stage4_test_landscapes.shape[0], 4)\n",
    "])\n",
    "\n",
    "# Check shapes\n",
    "print(\"Training Landscapes shape:\", train_landscapes.shape)\n",
    "print(\"Training Labels shape:\", train_labels.shape)\n",
    "print(\"Testing Landscapes shape:\", test_landscapes.shape)\n",
    "print(\"Testing Labels shape:\", test_labels.shape)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200, 'oob_score': True}\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.5152\n",
      "Mean Squared Error (MSE): 1.2626\n",
      "Log Loss: 1.2426\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.73      0.53      0.62        30\n",
      "           3       0.00      0.00      0.00        27\n",
      "           4       0.49      1.00      0.66        35\n",
      "\n",
      "    accuracy                           0.52        99\n",
      "   macro avg       0.31      0.38      0.32        99\n",
      "weighted avg       0.39      0.52      0.42        99\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  3  1  3]\n",
      " [ 0 16  1 13]\n",
      " [ 4  3  0 20]\n",
      " [ 0  0  0 35]]\n",
      "Elapsed time: 0.13 seconds\n",
      "OOB Score: 0.9561\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],            # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum samples to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'oob_score': [True]         # Minimum samples at a leaf node\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation for Hyperparameter Tuning\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "grid_search.fit(train_landscapes, train_labels)\n",
    "\n",
    "# Get the best model from Grid Search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the best model on training data\n",
    "best_rf_model.fit(train_landscapes, train_labels)\n",
    "\n",
    "# Evaluate the best model\n",
    "train_predictions = best_rf_model.predict(train_landscapes)\n",
    "test_predictions = best_rf_model.predict(test_landscapes)\n",
    "test_probabilities = best_rf_model.predict_proba(test_landscapes)\n",
    "\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "classification_rep = classification_report(test_labels, test_predictions)\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(test_labels, np.argmax(test_probabilities, axis=1))\n",
    "logloss = log_loss(test_labels, test_probabilities)\n",
    "\n",
    "# Display results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Display OOB score\n",
    "if hasattr(best_rf_model, 'oob_score_') and best_rf_model.oob_score_:\n",
    "    print(f\"OOB Score: {best_rf_model.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 CV Results:\n",
      "    param_n_estimators param_max_depth  param_min_samples_split  \\\n",
      "29                 200              10                        2   \n",
      "65                 200              20                        2   \n",
      "2                  200            None                        2   \n",
      "38                 200              10                        2   \n",
      "11                 200            None                        2   \n",
      "56                 200              20                        2   \n",
      "31                 100              10                        5   \n",
      "1                  100            None                        2   \n",
      "55                 100              20                        2   \n",
      "4                  100            None                        5   \n",
      "\n",
      "    param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
      "29                       1         0.961272        0.008006   \n",
      "65                       2         0.961272        0.008006   \n",
      "2                        1         0.961272        0.008006   \n",
      "38                       2         0.961272        0.008006   \n",
      "11                       2         0.961272        0.008006   \n",
      "56                       1         0.961272        0.008006   \n",
      "31                       1         0.961239        0.008217   \n",
      "1                        1         0.958675        0.009607   \n",
      "55                       1         0.958675        0.009607   \n",
      "4                        1         0.958641        0.009775   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  \\\n",
      "29           0.948718           0.961538           0.961039   \n",
      "65           0.948718           0.961538           0.961039   \n",
      "2            0.948718           0.961538           0.961039   \n",
      "38           0.948718           0.961538           0.961039   \n",
      "11           0.948718           0.961538           0.961039   \n",
      "56           0.948718           0.961538           0.961039   \n",
      "31           0.961538           0.961538           0.961039   \n",
      "1            0.948718           0.961538           0.961039   \n",
      "55           0.948718           0.961538           0.961039   \n",
      "4            0.961538           0.961538           0.948052   \n",
      "\n",
      "    split3_test_score  split4_test_score  rank_test_score  \n",
      "29           0.974026           0.961039                1  \n",
      "65           0.974026           0.961039                1  \n",
      "2            0.974026           0.961039                1  \n",
      "38           0.974026           0.961039                1  \n",
      "11           0.974026           0.961039                1  \n",
      "56           0.974026           0.961039                1  \n",
      "31           0.974026           0.948052                7  \n",
      "1            0.974026           0.948052                8  \n",
      "55           0.974026           0.948052                8  \n",
      "4            0.974026           0.948052               10  \n"
     ]
    }
   ],
   "source": [
    "# Extract cross-validation results\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Convert results to a DataFrame for easier inspection\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Select and display important columns\n",
    "columns_to_display = [\n",
    "    'param_n_estimators',\n",
    "    'param_max_depth',\n",
    "    'param_min_samples_split',\n",
    "    'param_min_samples_leaf',\n",
    "    'mean_test_score',  # Average CV accuracy score for each parameter combination\n",
    "    'std_test_score',   # Standard deviation of the CV scores\n",
    "    'split0_test_score', \n",
    "    'split1_test_score', \n",
    "    'split2_test_score', \n",
    "    'split3_test_score', \n",
    "    'split4_test_score',\n",
    "     'rank_test_score'\n",
    "]\n",
    "# Filter the results and sort by rank_test_score\n",
    "cv_results_summary = cv_results_df[columns_to_display]\n",
    "cv_results_summary_sorted = cv_results_summary.sort_values(by='rank_test_score')\n",
    "\n",
    "# Save all results to a CSV file\n",
    "cv_results_summary_sorted.to_csv('results/dc_cv_results.csv', index=False)\n",
    "\n",
    "top_10_results = cv_results_summary_sorted.head(10)\n",
    "\n",
    "# Display the top 10 results in this notebook environment\n",
    "print(\"Top 10 CV Results:\")\n",
    "print(top_10_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
