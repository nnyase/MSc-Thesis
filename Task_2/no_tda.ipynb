{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/mhdtgbjj27j50r7jsrfv3dl00000gn/T/ipykernel_70147/3528077661.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_var_genes_data[\"phenotype\"] = phenotype.values\n"
     ]
    }
   ],
   "source": [
    "# Load data from cancer stages\n",
    "expression_matrix = pd.read_csv(\"../data/cancer_stage/fpkm_matrix.csv\", index_col=0)\n",
    "significant_genes = pd.read_csv(\"../data/cancer_stage/significant_genes.csv\", index_col=0)\n",
    "\n",
    "# Separate phenotype labels\n",
    "phenotype = expression_matrix[\"phenotype\"]\n",
    "expression_matrix = expression_matrix.drop(columns=[\"phenotype\"])\n",
    "\n",
    "# Select significant genes\n",
    "significant_gene_names = significant_genes.index\n",
    "sig_exp_matrix = expression_matrix[significant_gene_names.intersection(expression_matrix.columns)]\n",
    "\n",
    "top_var_genes_data = sig_exp_matrix\n",
    "gene_dict = {i: col_name for i, col_name in enumerate(top_var_genes_data.columns)}\n",
    "top_var_genes_data[\"phenotype\"] = phenotype.values\n",
    "\n",
    "stage1_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage1']\n",
    "stage2_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage2']\n",
    "stage3_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage3']\n",
    "stage4_top_var_genes_data = top_var_genes_data[top_var_genes_data['phenotype'] == 'Stage4']\n",
    "\n",
    "stage1_top_var_genes_data = stage1_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "stage2_top_var_genes_data = stage2_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "stage3_top_var_genes_data = stage3_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "stage4_top_var_genes_data = stage4_top_var_genes_data.drop(columns=[\"phenotype\"])\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets for stage 1\n",
    "stage1_train, stage1_test = train_test_split(\n",
    "    stage1_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets for stage 2\n",
    "stage2_train, stage2_test = train_test_split(\n",
    "    stage2_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets for stage 3\n",
    "stage3_train, stage3_test = train_test_split(\n",
    "    stage3_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets for stage 4\n",
    "stage4_train, stage4_test = train_test_split(\n",
    "    stage4_top_var_genes_data, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50, 'oob_score': True}\n",
      "Training Accuracy: 0.9587\n",
      "Test Accuracy: 0.4949\n",
      "Mean Squared Error (MSE): 1.6768\n",
      "Log Loss: 1.1777\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.14      0.25         7\n",
      "           2       0.49      0.57      0.52        30\n",
      "           3       0.50      0.26      0.34        27\n",
      "           4       0.49      0.69      0.57        35\n",
      "\n",
      "    accuracy                           0.49        99\n",
      "   macro avg       0.62      0.41      0.42        99\n",
      "weighted avg       0.53      0.49      0.47        99\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1  5  0  1]\n",
      " [ 0 17  2 11]\n",
      " [ 0  7  7 13]\n",
      " [ 0  6  5 24]]\n",
      "OOB Score: 0.3721\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_features = np.vstack([stage1_train, stage2_train, stage3_train, stage4_train])\n",
    "train_labels = np.concatenate([\n",
    "    np.full(stage1_train.shape[0], 1),  # Label 0 for SARC\n",
    "    np.full(stage2_train.shape[0], 2),  # Label 1 for ESCA\n",
    "    np.full(stage3_train.shape[0], 3),   # Label 2 for PCPG\n",
    "    np.full(stage4_train.shape[0], 4)\n",
    "])\n",
    "\n",
    "test_features = np.vstack([stage1_test, stage2_test, stage3_test, stage4_test])\n",
    "test_labels = np.concatenate([\n",
    "    np.full(stage1_test.shape[0], 1),  # Label 0 for SARC\n",
    "    np.full(stage2_test.shape[0], 2),  # Label 1 for ESCA\n",
    "    np.full(stage3_test.shape[0], 3),\n",
    "    np.full(stage4_test.shape[0], 4)   # Label 2 for PCPG\n",
    "])\n",
    "\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],            # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum samples to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4], \n",
    "    'oob_score': [True]         # Minimum samples at a leaf node\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation for Hyperparameter Tuning\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# Get the best model from Grid Search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the best model on training data\n",
    "best_rf_model.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate the best model\n",
    "train_predictions = best_rf_model.predict(train_features)\n",
    "test_predictions = best_rf_model.predict(test_features)\n",
    "test_probabilities = best_rf_model.predict_proba(test_features)\n",
    "\n",
    "train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "classification_rep = classification_report(test_labels, test_predictions)\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(test_labels, np.argmax(test_probabilities, axis=1))\n",
    "logloss = log_loss(test_labels, test_probabilities)\n",
    "\n",
    "# Display results\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Log Loss: {logloss:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Display OOB score\n",
    "if hasattr(best_rf_model, 'oob_score_') and best_rf_model.oob_score_:\n",
    "    print(f\"OOB Score: {best_rf_model.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 CV Results:\n",
      "    param_n_estimators param_max_depth  param_min_samples_split  \\\n",
      "21                  50            None                        5   \n",
      "72                  50              20                        2   \n",
      "18                  50            None                        2   \n",
      "75                  50              20                        5   \n",
      "65                 200              20                        2   \n",
      "11                 200            None                        2   \n",
      "31                 100              10                        5   \n",
      "30                  50              10                        5   \n",
      "38                 200              10                        2   \n",
      "53                 200              10                       10   \n",
      "\n",
      "    param_min_samples_leaf  mean_test_score  std_test_score  \\\n",
      "21                       4         0.407959        0.060407   \n",
      "72                       4         0.407959        0.060407   \n",
      "18                       4         0.407959        0.060407   \n",
      "75                       4         0.407959        0.060407   \n",
      "65                       2         0.402897        0.059479   \n",
      "11                       2         0.402897        0.059479   \n",
      "31                       1         0.397835        0.041947   \n",
      "30                       1         0.397802        0.046187   \n",
      "38                       2         0.397769        0.059815   \n",
      "53                       4         0.397669        0.060550   \n",
      "\n",
      "    split0_test_score  split1_test_score  split2_test_score  \\\n",
      "21           0.487179           0.448718           0.415584   \n",
      "72           0.487179           0.448718           0.415584   \n",
      "18           0.487179           0.448718           0.415584   \n",
      "75           0.487179           0.448718           0.415584   \n",
      "65           0.474359           0.410256           0.441558   \n",
      "11           0.474359           0.410256           0.441558   \n",
      "31           0.423077           0.410256           0.454545   \n",
      "30           0.435897           0.410256           0.454545   \n",
      "38           0.461538           0.397436           0.415584   \n",
      "53           0.500000           0.397436           0.402597   \n",
      "\n",
      "    split3_test_score  split4_test_score  rank_test_score  \n",
      "21           0.311688           0.376623                1  \n",
      "72           0.311688           0.376623                1  \n",
      "18           0.311688           0.376623                1  \n",
      "75           0.311688           0.376623                1  \n",
      "65           0.298701           0.389610                5  \n",
      "11           0.298701           0.389610                5  \n",
      "31           0.337662           0.363636                7  \n",
      "30           0.350649           0.337662                8  \n",
      "38           0.285714           0.428571                9  \n",
      "53           0.311688           0.376623               10  \n"
     ]
    }
   ],
   "source": [
    "# Extract cross-validation results\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Convert results to a DataFrame for easier inspection\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Select and display important columns\n",
    "columns_to_display = [\n",
    "    'param_n_estimators',\n",
    "    'param_max_depth',\n",
    "    'param_min_samples_split',\n",
    "    'param_min_samples_leaf',\n",
    "    'mean_test_score',  # Average CV accuracy score for each parameter combination\n",
    "    'std_test_score',   # Standard deviation of the CV scores\n",
    "    'split0_test_score', \n",
    "    'split1_test_score', \n",
    "    'split2_test_score', \n",
    "    'split3_test_score', \n",
    "    'split4_test_score',\n",
    "     'rank_test_score'\n",
    "]\n",
    "# Filter the results and sort by rank_test_score\n",
    "cv_results_summary = cv_results_df[columns_to_display]\n",
    "cv_results_summary_sorted = cv_results_summary.sort_values(by='rank_test_score')\n",
    "\n",
    "# Save all results to a CSV file\n",
    "cv_results_summary_sorted.to_csv('results/no_tda_cv_results.csv', index=False)\n",
    "\n",
    "top_10_results = cv_results_summary_sorted.head(10)\n",
    "\n",
    "# Display the top 10 results in this notebook environment\n",
    "print(\"Top 10 CV Results:\")\n",
    "print(top_10_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
